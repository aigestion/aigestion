# ðŸŒŒ [GOD MODE] Cloud Build Pipeline - ML Service
# Optimized for: Python/FastAPI ML Inference

steps:
  # Step 1: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args:
      - 'build'
      - '--tag'
      - 'gcr.io/$PROJECT_ID/ml-service:$BUILD_ID'
      - '--tag'
      - 'gcr.io/$PROJECT_ID/ml-service:latest'
      - '--file'
      - 'Dockerfile'
      - '.'

  # Step 2: Push to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-image'
    args:
      - 'push'
      - '--all-tags'
      - 'gcr.io/$PROJECT_ID/ml-service'
    waitFor: ['build-image']

  # Step 3: Deploy to Cloud Run with God Mode configuration
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy-service'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'ml-service-aigestion'
      - '--image'
      - 'gcr.io/$PROJECT_ID/ml-service:$BUILD_ID'
      - '--region'
      - 'europe-southwest1'
      - '--platform'
      - 'managed'
      # God Mode: Resource Configuration
      - '--cpu'
      - '2'
      - '--memory'
      - '2Gi'
      - '--cpu-boost'
      - '--execution-environment'
      - 'gen2'
      # God Mode: Autoscaling
      - '--min-instances'
      - '1'
      - '--max-instances'
      - '10'
      - '--concurrency'
      - '80'
      # Networking & Security
      - '--port'
      - '8000'
      - '--allow-unauthenticated'
      - '--ingress'
      - 'all'
      # Timeout
      - '--timeout'
      - '300'
    waitFor: ['push-image']

# Build options
options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY

# Timeout for entire build
timeout: '1200s'

# Images to push (for caching)
images:
  - 'gcr.io/$PROJECT_ID/ml-service:$BUILD_ID'
  - 'gcr.io/$PROJECT_ID/ml-service:latest'
