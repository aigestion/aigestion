{"file":"C:\\Users\\Alejandro\\AIGestion\\backend\\src\\services\\vector.service.ts","mappings":";;;;;;;;;AAAA,yCAAuC;AACvC,4CAAyC;AACzC,wDAA8C;AAUvC,IAAM,aAAa,GAAnB,MAAM,aAAa;IACP,QAAQ,GAAW,OAAO,CAAC,GAAG,CAAC,kBAAkB,IAAI,UAAU,CAAC;IAEjF;;OAEG;IACH,KAAK,CAAC,MAAM,CAAC,GAAmB;QAC9B,IAAI,CAAC;YACH,eAAM,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,GAAG,CAAC,EAAE,EAAE,QAAQ,EAAE,IAAI,CAAC,QAAQ,EAAE,EAAE,4BAA4B,CAAC,CAAC;YAEtF,kDAAkD;YAClD,2EAA2E;YAE3E,oDAAoD;YACpD,MAAM,SAAS,GAAG,cAAc,GAAG,CAAC,EAAE,EAAE,CAAC;YACzC,MAAM,oBAAK,CAAC,GAAG,CACb,SAAS,EACT;gBACE,GAAG,GAAG;gBACN,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;aACtB,EACD,EAAE,GAAG,EAAE,CAAC,EAAE,CACX,CAAC,CAAC,uBAAuB;YAE1B,OAAO,IAAI,CAAC;QACd,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,eAAM,CAAC,KAAK,CAAC,EAAE,KAAK,EAAE,KAAK,EAAE,GAAG,CAAC,EAAE,EAAE,EAAE,kCAAkC,CAAC,CAAC;YAC3E,OAAO,KAAK,CAAC;QACf,CAAC;IACH,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,MAAM,CAAC,KAAa,EAAE,QAAgB,CAAC;QAC3C,IAAI,CAAC;YACH,eAAM,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,yBAAyB,CAAC,CAAC;YAEzD,uEAAuE;YACvE,4CAA4C;YAC5C,OAAO;gBACL;oBACE,EAAE,EAAE,mBAAmB;oBACvB,IAAI,EAAE,oEAAoE;oBAC1E,KAAK,EAAE,IAAI;iBACZ;aACF,CAAC;QACJ,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,eAAM,CAAC,KAAK,CAAC,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE,+BAA+B,CAAC,CAAC;YAChE,OAAO,EAAE,CAAC;QACZ,CAAC;IACH,CAAC;CACF,CAAA;AApDY,sCAAa;wBAAb,aAAa;IADzB,IAAA,sBAAU,GAAE;GACA,aAAa,CAoDzB;AAEY,QAAA,aAAa,GAAG,IAAI,aAAa,EAAE,CAAC","names":[],"sources":["C:\\Users\\Alejandro\\AIGestion\\backend\\src\\services\\vector.service.ts"],"sourcesContent":["import { injectable } from 'inversify';\nimport { logger } from '../utils/logger';\nimport { cache } from '../utils/cacheManager';\n\nexport interface VectorDocument {\n  id: string;\n  text: string;\n  metadata: Record<string, any>;\n  embedding?: number[];\n}\n\n@injectable()\nexport class VectorService {\n  private readonly provider: string = process.env.VECTOR_DB_PROVIDER || 'pinecone';\n\n  /**\n   * Index a document into the long-term memory\n   */\n  async upsert(doc: VectorDocument) {\n    try {\n      logger.info({ docId: doc.id, provider: this.provider }, 'Upserting to Vector Memory');\n\n      // 1. Generate Embedding (Simulated for this jump)\n      // In production: const embedding = await openAI.createEmbedding(doc.text);\n\n      // 2. Storage Logic (Simulated for initial scaffold)\n      const vectorKey = `vector:mem:${doc.id}`;\n      await cache.set(\n        vectorKey,\n        {\n          ...doc,\n          indexedAt: Date.now(),\n        },\n        { ttl: 0 },\n      ); // Circular persistence\n\n      return true;\n    } catch (error) {\n      logger.error({ error, docId: doc.id }, 'Error upserting to Vector Memory');\n      return false;\n    }\n  }\n\n  /**\n   * Semantic search for relevant context\n   */\n  async search(query: string, limit: number = 5) {\n    try {\n      logger.info({ query, limit }, 'Searching Vector Memory');\n\n      // In production: perform cosine similarity search in Pinecone/Weaviate\n      // For now, we return a symbolic context hit\n      return [\n        {\n          id: 'ref-Q1-milestones',\n          text: 'The Q1 2026 Roadmap focused on NestJS and Atomic Design System v2.',\n          score: 0.98,\n        },\n      ];\n    } catch (error) {\n      logger.error({ error, query }, 'Error searching Vector Memory');\n      return [];\n    }\n  }\n}\n\nexport const vectorService = new VectorService();\n"],"version":3}